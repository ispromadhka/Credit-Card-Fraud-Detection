{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ispromadhka/Credit-Card-Fraud-Detection/blob/main/Credit_Card_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPmytxL2MS0P"
      },
      "source": [
        "# üí≥ Credit Card Fraud Detection with Advanced ML\n",
        "\n",
        "---\n",
        "\n",
        "### üìö Table of Contents\n",
        "\n",
        "1. [Introduction & Business Context](#introduction)\n",
        "\n",
        "2. [Data Loading & Initial Exploration](#data-loading)\n",
        "\n",
        "3. [Exploratory Data Analysis](#eda)\n",
        "\n",
        "4. [Feature Engineering](#feature-engineering)\n",
        "\n",
        "5. [Model Development](#model-development)\n",
        "\n",
        "6. [Model Evaluation & Interpretability](#evaluation)\n",
        "\n",
        "7. [Business Impact Analysis](#business-impact)\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4D9ROazMS0a"
      },
      "source": [
        "<a id='introduction'></a>\n",
        "## 1. Introduction & Business Context üìä\n",
        "\n",
        "###  Problem Statement\n",
        "\n",
        "Credit card fraud is a significant challenge in the financial industry, causing billions in losses annually. This project develops a sophisticated fraud detection system using:\n",
        "\n",
        "- **CatBoost** (Yandex's gradient boosting library)\n",
        "\n",
        "- **SHAP** for model interpretability\n",
        "\n",
        "- **Optuna** for hyperparameter optimization\n",
        "\n",
        "\n",
        "\n",
        "###  Success Metrics\n",
        "\n",
        "- **Primary**: PR-AUC (critical for imbalanced data)\n",
        "\n",
        "- **Secondary**: ROC-AUC, F1-Score, Business ROI\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost optuna imblearn shap kagglehub"
      ],
      "metadata": {
        "id": "B89ur0HNMcGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQrzP-_cMS0b"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score, f1_score,\n",
        "    confusion_matrix, classification_report, roc_curve,\n",
        "    precision_recall_curve, precision_score, recall_score\n",
        ")\n",
        "\n",
        "import optuna\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import shap\n",
        "\n",
        "import kagglehub\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 11\n",
        "plt.rcParams['axes.labelsize'] = 12\n",
        "plt.rcParams['axes.titlesize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 10\n",
        "plt.rcParams['ytick.labelsize'] = 10\n",
        "plt.rcParams['legend.fontsize'] = 10\n",
        "plt.rcParams['figure.titlesize'] = 16\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HeI8OjbMS0c"
      },
      "source": [
        "<a id='data-loading'></a>\n",
        "## 2. Data Loading & Initial Overview üìÅ\n",
        "\n",
        "We'll use the famous Credit Card Fraud Detection dataset from Kaggle, containing:\n",
        "\n",
        "- **284,807** transactions\n",
        "\n",
        "- **492** fraudulent transactions (0.17% - extreme imbalance!)\n",
        "\n",
        "- **30** features (V1-V28 are PCA-transformed for privacy, plus Time and Amount)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMCfTiWSMS0d"
      },
      "outputs": [],
      "source": [
        "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "df = pd.read_csv(f\"{path}/creditcard.csv\")\n",
        "\n",
        "print(f\"\\n Dataset Shape: {df.shape[0]:,} transactions √ó {df.shape[1]} features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J85eLc8EMS0f"
      },
      "outputs": [],
      "source": [
        "print(\"\\n Dataset Info:\")\n",
        "display(df.head())\n",
        "display(df.info())\n",
        "print(\"\\nüìà Statistical Summary:\")\n",
        "display(df.describe().round(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vp0Vm6PMS0g"
      },
      "source": [
        "<a id='eda'></a>\n",
        "## 3. Exploratory Data Analysis üîç\n",
        "\n",
        "### Key Questions to Answer:\n",
        "\n",
        "1. How severe is the class imbalance?\n",
        "\n",
        "2. What are the distributions of Amount and Time?\n",
        "\n",
        "3. Are there any obvious patterns in fraudulent transactions?\n",
        "\n",
        "4. Do we have missing values or outliers to handle?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing Values Check"
      ],
      "metadata": {
        "id": "ljr8JFwrU-rR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zduVcqUpMS0i"
      },
      "outputs": [],
      "source": [
        "missing = df.isnull().sum()\n",
        "if missing.any():\n",
        "    display(missing[missing > 0])\n",
        "else:\n",
        "    print(\"‚úÖ No missing values found - Data quality is excellent!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class Distribution Analysis"
      ],
      "metadata": {
        "id": "qa6GISaoVIuH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiHhcCVWMS0j"
      },
      "outputs": [],
      "source": [
        "fraud_count = df['Class'].sum()\n",
        "normal_count = len(df) - fraud_count\n",
        "fraud_ratio = df['Class'].mean()\n",
        "\n",
        "print(f\"üîµ Normal Transactions: {normal_count:,} ({(1-fraud_ratio)*100:.2f}%)\")\n",
        "print(f\"üî¥ Fraud Transactions: {fraud_count:,} ({fraud_ratio*100:.2f}%)\")\n",
        "print(f\"‚öñÔ∏è Imbalance Ratio: 1:{int(normal_count/fraud_count)}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "ax = axes[0]\n",
        "class_data = pd.DataFrame({\n",
        "    'Class': ['Normal', 'Fraud'],\n",
        "    'Count': [normal_count, fraud_count],\n",
        "    'Percentage': [(1-fraud_ratio)*100, fraud_ratio*100]\n",
        "})\n",
        "\n",
        "bars = ax.bar(class_data['Class'], class_data['Count'],\n",
        "               color=['#2E86C1', '#E74C3C'], alpha=0.8, edgecolor='black')\n",
        "\n",
        "for bar, count, pct in zip(bars, class_data['Count'], class_data['Percentage']):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{count:,}\\n({pct:.2f}%)',\n",
        "            ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "ax.set_ylabel('Number of Transactions', fontsize=12)\n",
        "ax.set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
        "ax.set_ylim(0, normal_count * 1.1)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[1]\n",
        "colors = ['#2E86C1', '#E74C3C']\n",
        "explode = (0, 0.1)\n",
        "\n",
        "wedges, texts, autotexts = ax.pie(\n",
        "    [normal_count, fraud_count],\n",
        "    labels=['Normal', 'Fraud'],\n",
        "    colors=colors,\n",
        "    explode=explode,\n",
        "    autopct=lambda pct: f'{pct:.2f}%\\n({int(pct/100 * len(df)):,})',\n",
        "    startangle=90,\n",
        "    shadow=True\n",
        ")\n",
        "\n",
        "for autotext in autotexts:\n",
        "    autotext.set_color('white')\n",
        "    autotext.set_fontweight('bold')\n",
        "\n",
        "ax.set_title('Transaction Type Proportion', fontsize=14, fontweight='bold')\n",
        "\n",
        "ax = axes[2]\n",
        "ax.bar(['Normal', 'Fraud'], [normal_count, fraud_count],\n",
        "       color=['#2E86C1', '#E74C3C'], alpha=0.8, edgecolor='black')\n",
        "ax.set_yscale('log')\n",
        "ax.set_ylabel('Number of Transactions (log scale)', fontsize=12)\n",
        "ax.set_title('Class Distribution (Log Scale)', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3, which='both')\n",
        "\n",
        "for i, (label, value) in enumerate(zip(['Normal', 'Fraud'], [normal_count, fraud_count])):\n",
        "    ax.text(i, value, f'{value:,}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.suptitle('üéØ Class Imbalance Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fraud_count = df['Class'].sum()\n",
        "normal_count = len(df) - fraud_count\n",
        "fraud_ratio = df['Class'].mean()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "ax = axes[0]\n",
        "class_data = pd.DataFrame({\n",
        "      'Class': ['Normal', 'Fraud'],\n",
        "      'Count': [normal_count, fraud_count],\n",
        "      'Percentage': [(1-fraud_ratio)*100, fraud_ratio*100]\n",
        "  })\n",
        "\n",
        "bars = ax.bar(class_data['Class'], class_data['Count'],\n",
        "                 color=['#2E86C1', '#E74C3C'], alpha=0.8, edgecolor='black')\n",
        "\n",
        "for bar, count, pct in zip(bars, class_data['Count'],\n",
        "class_data['Percentage']):\n",
        "      height = bar.get_height()\n",
        "      ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "              f'{count:,}\\n({pct:.2f}%)',\n",
        "              ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "ax.set_ylabel('Number of Transactions', fontsize=12)\n",
        "ax.set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
        "ax.set_ylim(0, normal_count * 1.1)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "\n",
        "ax = axes[1]\n",
        "ax.bar(['Normal', 'Fraud'], [normal_count, fraud_count],\n",
        "         color=['#2E86C1', '#E74C3C'], alpha=0.8, edgecolor='black')\n",
        "ax.set_yscale('log')\n",
        "ax.set_ylabel('Number of Transactions (log scale)', fontsize=12)\n",
        "ax.set_title('Class Distribution (Log Scale)', fontsize=14,fontweight='bold')\n",
        "ax.grid(True, alpha=0.3, which='both')\n",
        "\n",
        "for i, (label, value) in enumerate(zip(['Normal', 'Fraud'], [normal_count,\n",
        "   fraud_count])):\n",
        "    ax.text(i, value, f'{value:,}', ha='center', va='bottom',\n",
        "fontweight='bold')\n",
        "\n",
        "plt.suptitle(f'Class Imbalance Analysis\\n Imbalance Ratio: 1:{int(normal_count/fraud_count)}', fontsize=16,fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q_yPU2qxN8rY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transaction Amount Analysis"
      ],
      "metadata": {
        "id": "2MSVM2aWU2H9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mharj_0FMS0l"
      },
      "outputs": [],
      "source": [
        "stats_data = []\n",
        "\n",
        "for class_label in [0, 1]:\n",
        "    class_name = 'Normal' if class_label == 0 else 'Fraud'\n",
        "    class_data = df[df['Class'] == class_label]['Amount']\n",
        "\n",
        "    stats_data.append({\n",
        "        'Type': class_name,\n",
        "        'Mean ($)': f\"{class_data.mean():.2f}\",\n",
        "        'Median ($)': f\"{class_data.median():.2f}\",\n",
        "        'Std Dev ($)': f\"{class_data.std():.2f}\",\n",
        "        'Min ($)': f\"{class_data.min():.2f}\",\n",
        "        'Max ($)': f\"{class_data.max():.2f}\",\n",
        "        'Count': f\"{len(class_data):,}\"\n",
        "    })\n",
        "\n",
        "stats_df = pd.DataFrame(stats_data)\n",
        "display(stats_df)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "ax = axes[0]\n",
        "data_to_plot = [df[df['Class'] == 0]['Amount'].values,\n",
        "                df[df['Class'] == 1]['Amount'].values]\n",
        "bp = ax.boxplot(data_to_plot, labels=['Normal', 'Fraud'],\n",
        "                patch_artist=True, showmeans=True)\n",
        "colors = ['#2E86C1', '#E74C3C']\n",
        "for patch, color in zip(bp['boxes'], colors):\n",
        "    patch.set_facecolor(color)\n",
        "    patch.set_alpha(0.7)\n",
        "ax.set_ylabel('Transaction Amount ($)')\n",
        "ax.set_title('Amount Distribution Comparison', fontweight='bold')\n",
        "ax.set_yscale('log')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[1]\n",
        "sample_indices = np.random.choice(df[df['Class'] == 0].index, 5000,\n",
        "                                  replace=False)\n",
        "ax.scatter(df.loc[sample_indices, 'Time'] / 3600,\n",
        "           df.loc[sample_indices, 'Amount'],\n",
        "           alpha=0.3, s=10, label='Normal', color='#2E86C1')\n",
        "ax.scatter(df[df['Class'] == 1]['Time'] / 3600,\n",
        "           df[df['Class'] == 1]['Amount'],\n",
        "           alpha=0.8, s=20, label='Fraud', color='#E74C3C', marker='x')\n",
        "ax.set_xlabel('Time (hours)')\n",
        "ax.set_ylabel('Amount ($)')\n",
        "ax.set_title('Transaction Pattern: Amount vs Time', fontweight='bold')\n",
        "ax.set_yscale('log')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('üí∞ Transaction Patterns Analysis', fontsize=16,\n",
        "             fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA Features Analysis (V1-V28):"
      ],
      "metadata": {
        "id": "TNi_RtanUxjh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S61vwT4JMS0n"
      },
      "outputs": [],
      "source": [
        "v_cols = [col for col in df.columns if col.startswith('V')]\n",
        "\n",
        "correlations = []\n",
        "for col in v_cols:\n",
        "    corr = df[col].corr(df['Class'])\n",
        "    correlations.append((col, corr))\n",
        "\n",
        "correlations.sort(key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "print(\"\\nüéØ Top 10 Features Most Correlated with Fraud:\")\n",
        "for i, (col, corr) in enumerate(correlations[:10], 1):\n",
        "    direction = \"up\" if corr > 0 else \"down\"\n",
        "    print(f\"  {i}. {col}: {corr:+.4f} {direction}\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "top_features = [col for col, _ in correlations[:15]] + ['Amount', 'Class']\n",
        "corr_matrix = df[top_features].corr()\n",
        "\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f',\n",
        "            cmap='coolwarm', center=0, square=True, linewidths=1,\n",
        "            cbar_kws={\"shrink\": 0.8})\n",
        "\n",
        "plt.title('Correlation Matrix: Top Features vs Fraud',\n",
        "          fontsize=12, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwslAwYhMS0n"
      },
      "source": [
        "<a id='feature-engineering'></a>\n",
        "## 4. Feature Engineering üîß\n",
        "\n",
        "### Strategy:\n",
        "\n",
        "1. **Time-based features**: Extract hour and day patterns\n",
        "\n",
        "2. **Amount transformations**: Log transform, polynomial features\n",
        "\n",
        "3. **Statistical aggregations**: Mean, std, min, max of V features\n",
        "\n",
        "4. **Anomaly scores**: Z-scores for key features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDPu4IcYMS0o"
      },
      "outputs": [],
      "source": [
        "def create_advanced_features(df):\n",
        "    print(\"üîß Feature Engineering Pipeline\")\n",
        "\n",
        "    df_feat = df.copy()\n",
        "    original_features = len(df.columns)\n",
        "\n",
        "    print(\"\\n‚è∞ Creating time-based features...\")\n",
        "    df_feat['Hour'] = (df_feat['Time'] / 3600) % 24\n",
        "    df_feat['Day'] = df_feat['Time'] / (3600 * 24)\n",
        "    df_feat['Hour_sin'] = np.sin(2 * np.pi * df_feat['Hour'] / 24)\n",
        "    df_feat['Hour_cos'] = np.cos(2 * np.pi * df_feat['Hour'] / 24)\n",
        "    df_feat['Is_Weekend'] = (df_feat['Day'] % 7 >= 5).astype(int)\n",
        "    df_feat['Is_Night'] = ((df_feat['Hour'] >= 22) | (df_feat['Hour'] <= 6)).astype(int)\n",
        "\n",
        "    print(\"üí∞ Creating amount-based features...\")\n",
        "    df_feat['Amount_log'] = np.log1p(df_feat['Amount'])\n",
        "    df_feat['Amount_squared'] = df_feat['Amount'] ** 2\n",
        "    df_feat['Amount_sqrt'] = np.sqrt(df_feat['Amount'])\n",
        "\n",
        "    df_feat['Amount_bin'] = pd.qcut(df_feat['Amount'], q=10, labels=False, duplicates='drop')\n",
        "\n",
        "    print(\"üìä Creating statistical aggregations...\")\n",
        "    v_cols = [col for col in df.columns if col.startswith('V')]\n",
        "\n",
        "    df_feat['V_mean'] = df_feat[v_cols].mean(axis=1)\n",
        "    df_feat['V_std'] = df_feat[v_cols].std(axis=1)\n",
        "    df_feat['V_max'] = df_feat[v_cols].max(axis=1)\n",
        "    df_feat['V_min'] = df_feat[v_cols].min(axis=1)\n",
        "    df_feat['V_range'] = df_feat['V_max'] - df_feat['V_min']\n",
        "    df_feat['V_skew'] = df_feat[v_cols].skew(axis=1)\n",
        "    df_feat['V_kurtosis'] = df_feat[v_cols].kurtosis(axis=1)\n",
        "\n",
        "    print(\"üéØ Creating anomaly scores...\")\n",
        "    important_features = ['V1', 'V2', 'V3', 'V4', 'V11', 'V12', 'V14', 'V17']\n",
        "\n",
        "    for col in important_features:\n",
        "        mean = df_feat[col].mean()\n",
        "        std = df_feat[col].std()\n",
        "        df_feat[f'{col}_zscore'] = (df_feat[col] - mean) / std\n",
        "        df_feat[f'{col}_is_outlier'] = (np.abs(df_feat[f'{col}_zscore']) > 3).astype(int)\n",
        "\n",
        "    print(\"üîÑ Creating interaction features...\")\n",
        "    df_feat['Amount_x_V1'] = df_feat['Amount'] * df_feat['V1']\n",
        "    df_feat['Amount_x_V2'] = df_feat['Amount'] * df_feat['V2']\n",
        "    df_feat['Hour_x_Amount'] = df_feat['Hour'] * df_feat['Amount']\n",
        "\n",
        "    outlier_cols = [col for col in df_feat.columns if col.endswith('_is_outlier')]\n",
        "    df_feat['Total_outliers'] = df_feat[outlier_cols].sum(axis=1)\n",
        "\n",
        "    new_features = len(df_feat.columns) - original_features\n",
        "\n",
        "    print(f\"\\n‚úÖ Feature Engineering Complete!\")\n",
        "    print(f\"   - Original features: {original_features}\")\n",
        "    print(f\"   - New features created: {new_features}\")\n",
        "    print(f\"   - Total features: {len(df_feat.columns)}\")\n",
        "\n",
        "    return df_feat\n",
        "\n",
        "df_engineered = create_advanced_features(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FIh_oV5MS0p"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "ax = axes[0, 0]\n",
        "for class_label, class_name, color in [(0, 'Normal', '#2E86C1'),\n",
        "                                        (1, 'Fraud', '#E74C3C')]:\n",
        "    hour_dist = df_engineered[df_engineered['Class']==class_label]['Hour']\n",
        "    ax.hist(hour_dist, bins=24, alpha=0.7, label=class_name,\n",
        "            color=color, density=True)\n",
        "\n",
        "ax.set_xlabel('Hour of Day')\n",
        "ax.set_ylabel('Density')\n",
        "ax.set_title('Transaction Distribution by Hour', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[0, 1]\n",
        "for class_label, class_name, color in [(0, 'Normal', '#2E86C1'),\n",
        "                                        (1, 'Fraud', '#E74C3C')]:\n",
        "    amount_log = df_engineered[df_engineered['Class']==class_label]['Amount_log']\n",
        "    ax.hist(amount_log, bins=50, alpha=0.7, label=class_name,\n",
        "            color=color, density=True)\n",
        "\n",
        "ax.set_xlabel('Log(Amount + 1)')\n",
        "ax.set_ylabel('Density')\n",
        "ax.set_title('Log-Transformed Amount Distribution', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[1, 0]\n",
        "stats_features = ['V_mean', 'V_std', 'V_range']\n",
        "positions = np.arange(len(stats_features))\n",
        "width = 0.35\n",
        "\n",
        "normal_means = [df_engineered[df_engineered['Class']==0][feat].mean()\n",
        "                for feat in stats_features]\n",
        "fraud_means = [df_engineered[df_engineered['Class']==1][feat].mean()\n",
        "               for feat in stats_features]\n",
        "\n",
        "ax.bar(positions - width/2, normal_means, width, label='Normal',\n",
        "       color='#2E86C1', alpha=0.8)\n",
        "ax.bar(positions + width/2, fraud_means, width, label='Fraud',\n",
        "       color='#E74C3C', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Statistical Features')\n",
        "ax.set_ylabel('Mean Value')\n",
        "ax.set_title('V-Features Statistics by Class', fontweight='bold')\n",
        "ax.set_xticks(positions)\n",
        "ax.set_xticklabels(stats_features)\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[1, 1]\n",
        "for class_label, class_name, color in [(0, 'Normal', '#2E86C1'),\n",
        "                                        (1, 'Fraud', '#E74C3C')]:\n",
        "    outlier_counts = df_engineered[df_engineered['Class']==class_label]['Total_outliers']\n",
        "    ax.hist(outlier_counts, bins=range(0, 10), alpha=0.7, label=class_name,\n",
        "            color=color, density=True)\n",
        "\n",
        "ax.set_xlabel('Number of Outlier Features')\n",
        "ax.set_ylabel('Density')\n",
        "ax.set_title('Outlier Count Distribution by Class', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Engineered Features Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOpyXSwMS0p"
      },
      "source": [
        "<a id='model-development'></a>\n",
        "## 5. Model Development ü§ñ\n",
        "\n",
        "### Approach:\n",
        "\n",
        "1. **Train-Validation-Test Split** (60-20-20)\n",
        "\n",
        "2. **Imbalance Handling**: Compare no sampling, SMOTE, and undersampling\n",
        "\n",
        "3. **Model**: CatBoost with class weights\n",
        "\n",
        "4. **Optimization**: Optuna for hyperparameter tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing Data for Modeling"
      ],
      "metadata": {
        "id": "yzAjZSoRXpen"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THUQWK1xMS0p"
      },
      "outputs": [],
      "source": [
        "X = df_engineered.drop(['Class', 'Time'], axis=1)\n",
        "y = df_engineered['Class']\n",
        "\n",
        "print(f\"\\nüìä Feature Matrix Shape: {X.shape}\")\n",
        "print(f\"üéØ Target Distribution: {y.value_counts().to_dict()}\")\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Data Split Complete:\")\n",
        "print(f\"    Training Set: {X_train.shape[0]:,} samples ({y_train.mean()*100:.2f}% fraud)\")\n",
        "print(f\"    Validation Set: {X_val.shape[0]:,} samples ({y_val.mean()*100:.2f}% fraud)\")\n",
        "print(f\"    Test Set: {X_test.shape[0]:,} samples ({y_test.mean()*100:.2f}% fraud)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = CatBoostClassifier(\n",
        "    iterations=200,\n",
        "    learning_rate=0.01,\n",
        "    depth=8,\n",
        "    l2_leaf_reg=3,\n",
        "    loss_function='Logloss',\n",
        "    eval_metric='PRAUC',\n",
        "    random_seed=42,\n",
        "    bootstrap_type='Bayesian',\n",
        "    class_weights={0: 1, 1: 250},\n",
        "    use_best_model=True\n",
        ")\n",
        "\n",
        "baseline_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=(X_val, y_val),\n",
        "    early_stopping_rounds=50,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "y_val_pred = baseline_model.predict(X_val)\n",
        "y_val_proba = baseline_model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "baseline_metrics = {\n",
        "    'ROC-AUC': roc_auc_score(y_val, y_val_proba),\n",
        "    'PR-AUC': average_precision_score(y_val, y_val_proba),\n",
        "    'F1-Score': f1_score(y_val, y_val_pred),\n",
        "    'Precision': precision_score(y_val, y_val_pred),\n",
        "    'Recall': recall_score(y_val, y_val_pred)\n",
        "}\n",
        "\n",
        "print(\"\\nüìä Baseline Model Performance:\")\n",
        "for metric, value in baseline_metrics.items():\n",
        "    print(f\"    {metric}: {value:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_val, y_val_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(f\"\\nüìã Confusion Matrix:\")\n",
        "print(f\"    True Positives: {tp} | False Positives: {fp}\")\n",
        "print(f\"    False Negatives: {fn} | True Negatives: {tn}\")\n",
        "\n",
        "print(f\"\\nüíº Business Metrics:\")\n",
        "print(f\"    Fraud Detection Rate: {tp/(tp+fn)*100:.1f}%\")\n",
        "print(f\"    Alert Accuracy: {tp/(tp+fp)*100:.1f}%\")\n",
        "print(f\"    False Positive Rate: {fp/(fp+tn)*100:.3f}%\")\n",
        "print(f\"    Missed Fraud: {fn} transactions\")"
      ],
      "metadata": {
        "id": "WC1jwJukihRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Optimization with Optuna"
      ],
      "metadata": {
        "id": "9Um-_GyFYP0m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pdj4P3qZMS0q"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'iterations': trial.suggest_int('iterations', 50, 500),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'depth': trial.suggest_int('depth', 4, 10),\n",
        "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
        "        'random_strength': trial.suggest_float('random_strength', 0, 1),\n",
        "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
        "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
        "        'loss_function': 'Logloss',\n",
        "        'eval_metric': 'AUC',\n",
        "        'random_seed': 42,\n",
        "        'verbose': False\n",
        "    }\n",
        "\n",
        "    class_weight = trial.suggest_float('class_weight', 50, 200)\n",
        "    params['class_weights'] = {0: 1, 1: class_weight}\n",
        "\n",
        "    model = CatBoostClassifier(**params)\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=(X_val, y_val),\n",
        "        early_stopping_rounds=20,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
        "    return average_precision_score(y_val, y_pred_proba)\n",
        "\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))\n",
        "study.optimize(objective, n_trials=10, show_progress_bar=True)\n",
        "\n",
        "print(f\"\\n‚úÖ Optimization Complete!\")\n",
        "print(f\"   Best PR-AUC: {study.best_value:.4f}\")\n",
        "print(f\"\\nüìã Best Parameters:\")\n",
        "for param, value in study.best_params.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"    {param}: {value:.4f}\")\n",
        "    else:\n",
        "        print(f\"    {param}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEvVKmJvMS0r"
      },
      "outputs": [],
      "source": [
        "best_params = study.best_params.copy()\n",
        "class_weight = best_params.pop('class_weight')\n",
        "best_params['class_weights'] = {0: 1, 1: class_weight}\n",
        "best_params['loss_function'] = 'Logloss'\n",
        "best_params['eval_metric'] = 'AUC'\n",
        "best_params['random_seed'] = 42\n",
        "best_params['verbose'] = False\n",
        "\n",
        "final_model = CatBoostClassifier(**best_params)\n",
        "final_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=(X_val, y_val),\n",
        "    early_stopping_rounds=30,\n",
        "    verbose=100\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9teSOkxSMS0r"
      },
      "source": [
        "<a id='evaluation'></a>\n",
        "## 6. Model Evaluation & Interpretability üìä\n",
        "\n",
        "### Comprehensive evaluation includes:\n",
        "\n",
        "1. Performance metrics (ROC-AUC, PR-AUC, F1, Presion, Recall)\n",
        "\n",
        "2. Confusion matrix analysis\n",
        "\n",
        "3. ROC and PR curves\n",
        "\n",
        "4. Feature importance\n",
        "\n",
        "5. SHAP analysis for interpretability\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ Final Model Evaluation on Test Set"
      ],
      "metadata": {
        "id": "2yDSgx913jkP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXfglcboMS0r"
      },
      "outputs": [],
      "source": [
        "y_test_pred = final_model.predict(X_test)\n",
        "y_test_proba = final_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "test_metrics = {\n",
        "    'ROC-AUC': roc_auc_score(y_test, y_test_proba),\n",
        "    'PR-AUC': average_precision_score(y_test, y_test_proba),\n",
        "    'F1-Score': f1_score(y_test, y_test_pred),\n",
        "    'Precision': (y_test_pred[y_test == 1] == 1).mean(),\n",
        "    'Recall': (y_test[y_test_pred == 1] == 1).mean()\n",
        "}\n",
        "\n",
        "print(\"\\nüìä Test Set Performance:\")\n",
        "for metric, value in test_metrics.items():\n",
        "    print(f\"    {metric}: {value:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(f\"\\nüìã Confusion Matrix Analysis:\")\n",
        "print(f\"    True Negatives: {tn:,} ({tn/(tn+fp)*100:.2f}%)\")\n",
        "print(f\"    False Positives: {fp:,} ({fp/(tn+fp)*100:.2f}%)\")\n",
        "print(f\"    False Negatives: {fn:,} ({fn/(fn+tp)*100:.2f}%)\")\n",
        "print(f\"    True Positives: {tp:,} ({tp/(fn+tp)*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILgV9rYlMS0r"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20, 12))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Normal', 'Fraud'],\n",
        "            yticklabels=['Normal', 'Fraud'],\n",
        "            cbar_kws={'label': 'Count'})\n",
        "ax1.set_ylabel('True Label')\n",
        "ax1.set_xlabel('Predicted Label')\n",
        "ax1.set_title('Confusion Matrix', fontweight='bold')\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        percentage = cm[i, j] / cm.sum() * 100\n",
        "        ax1.text(j + 0.5, i + 0.7, f'({percentage:.2f}%)',\n",
        "                ha='center', va='center', fontsize=9, color='red')\n",
        "\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "fpr, tpr, roc_thresholds = roc_curve(y_test, y_test_proba)\n",
        "roc_auc = roc_auc_score(y_test, y_test_proba)\n",
        "\n",
        "ax2.plot(fpr, tpr, color='#E74C3C', lw=2,\n",
        "         label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "ax2.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', alpha=0.5)\n",
        "ax2.fill_between(fpr, tpr, alpha=0.3, color='#E74C3C')\n",
        "ax2.set_xlim([0.0, 1.0])\n",
        "ax2.set_ylim([0.0, 1.05])\n",
        "ax2.set_xlabel('False Positive Rate')\n",
        "ax2.set_ylabel('True Positive Rate')\n",
        "ax2.set_title('ROC Curve', fontweight='bold')\n",
        "ax2.legend(loc=\"lower right\")\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "ax3 = fig.add_subplot(gs[0, 2])\n",
        "precision, recall, pr_thresholds = precision_recall_curve(y_test, y_test_proba)\n",
        "pr_auc = average_precision_score(y_test, y_test_proba)\n",
        "\n",
        "ax3.plot(recall, precision, color='#27AE60', lw=2,\n",
        "         label=f'PR curve (AUC = {pr_auc:.4f})')\n",
        "ax3.fill_between(recall, precision, alpha=0.3, color='#27AE60')\n",
        "ax3.axhline(y=y_test.mean(), color='navy', linestyle='--',\n",
        "            label=f'Baseline (Random): {y_test.mean():.4f}')\n",
        "ax3.set_xlabel('Recall')\n",
        "ax3.set_ylabel('Precision')\n",
        "ax3.set_title('Precision-Recall Curve', fontweight='bold')\n",
        "ax3.legend(loc=\"upper right\")\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "ax4 = fig.add_subplot(gs[1, :])\n",
        "feature_importance = final_model.get_feature_importance()\n",
        "feature_names = X_train.columns\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_names[:len(feature_importance)],\n",
        "    'importance': feature_importance\n",
        "}).sort_values('importance', ascending=False).head(20)\n",
        "\n",
        "colors = plt.cm.viridis(importance_df['importance'] / importance_df['importance'].max())\n",
        "bars = ax4.barh(range(len(importance_df)), importance_df['importance'], color=colors)\n",
        "ax4.set_yticks(range(len(importance_df)))\n",
        "ax4.set_yticklabels(importance_df['feature'])\n",
        "ax4.set_xlabel('Importance Score')\n",
        "ax4.set_title('Top 20 Feature Importances', fontweight='bold')\n",
        "ax4.invert_yaxis()\n",
        "ax4.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "for i, (bar, value) in enumerate(zip(bars, importance_df['importance'])):\n",
        "    ax4.text(value, i, f' {value:.1f}', va='center', fontsize=9)\n",
        "\n",
        "ax5 = fig.add_subplot(gs[2, 0])\n",
        "thresholds = np.linspace(0.1, 0.9, 50)\n",
        "metrics_by_threshold = []\n",
        "\n",
        "for threshold in thresholds:\n",
        "    y_pred_threshold = (y_test_proba >= threshold).astype(int)\n",
        "    metrics_by_threshold.append({\n",
        "        'threshold': threshold,\n",
        "        'precision': precision_score(y_test, y_pred_threshold, zero_division=0),\n",
        "        'recall': recall_score(y_test, y_pred_threshold),\n",
        "        'f1': f1_score(y_test, y_pred_threshold, zero_division=0)\n",
        "    })\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_by_threshold)\n",
        "ax2 = ax5.twinx()\n",
        "\n",
        "line1 = ax5.plot(metrics_df['threshold'], metrics_df['precision'],\n",
        "                'b-', linewidth=2, label='Precision')\n",
        "line2 = ax2.plot(metrics_df['threshold'], metrics_df['recall'],\n",
        "                 'r-', linewidth=2, label='Recall')\n",
        "ax5.plot(metrics_df['threshold'], metrics_df['f1'],\n",
        "         'g-', linewidth=2, label='F1-Score')\n",
        "\n",
        "ax5.set_xlabel('Threshold')\n",
        "ax5.set_ylabel('Score')\n",
        "ax5.set_title('Metrics by Decision Threshold', fontweight='bold')\n",
        "ax5.legend()\n",
        "ax5.grid(True, alpha=0.3)\n",
        "\n",
        "ax6 = fig.add_subplot(gs[2, 1])\n",
        "ax6.hist(y_test_proba[y_test == 0], bins=50, alpha=0.7,\n",
        "         label='Normal', color='#2E86C1', density=True)\n",
        "ax6.hist(y_test_proba[y_test == 1], bins=50, alpha=0.7,\n",
        "         label='Fraud', color='#E74C3C', density=True)\n",
        "ax6.set_xlabel('Predicted Probability')\n",
        "ax6.set_ylabel('Density')\n",
        "ax6.set_title('Score Distribution by Class', fontweight='bold')\n",
        "ax6.legend()\n",
        "ax6.grid(True, alpha=0.3)\n",
        "\n",
        "ax7 = fig.add_subplot(gs[2, 2])\n",
        "from sklearn.calibration import calibration_curve\n",
        "fraction_pos, mean_pred = calibration_curve(y_test, y_test_proba, n_bins=10)\n",
        "ax7.plot(mean_pred, fraction_pos, marker='o', linewidth=2,\n",
        "         label='Model', color='#E74C3C')\n",
        "ax7.plot([0, 1], [0, 1], linestyle='--', label='Perfect Calibration',\n",
        "         color='gray', alpha=0.5)\n",
        "ax7.set_xlabel('Mean Predicted Probability')\n",
        "ax7.set_ylabel('Fraction of Positives')\n",
        "ax7.set_title('Calibration Plot', fontweight='bold')\n",
        "ax7.legend()\n",
        "ax7.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Comprehensive Model Evaluation',\n",
        "             fontsize=18, fontweight='bold', y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîç SHAP Analysis for Model Interpretability"
      ],
      "metadata": {
        "id": "EjoOegzH9G99"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY9i4b2AMS0t"
      },
      "outputs": [],
      "source": [
        "sample_size = 1000\n",
        "X_test_sample = X_test.sample(n=min(sample_size, len(X_test)), random_state=42)\n",
        "\n",
        "explainer = shap.TreeExplainer(final_model)\n",
        "shap_values = explainer.shap_values(X_test_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt06DqpdMS0v"
      },
      "source": [
        "<a id='business-impact'></a>\n",
        "## 7. Business Impact Analysis üí∞\n",
        "\n",
        "### ROI Calculation:\n",
        "\n",
        "- **Prevented fraud loss**: $1,000 √ó True Positives √ó 1.5\n",
        "\n",
        "- **Investigation cost**: $50 √ó (True Positives + False Positives)\n",
        "\n",
        "- **Customer friction**: $100 √ó False Positives √ó 0.02\n",
        "\n",
        "- **Missed fraud**: $1,000 √ó False Negatives √ó 1.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBK2ZaqPMS0x"
      },
      "outputs": [],
      "source": [
        "def calculate_business_metrics(y_true, y_pred, y_proba):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "    avg_fraud_amount = 1000\n",
        "    investigation_cost = 50\n",
        "    fraud_multiplier = 1.5\n",
        "    friction_rate = 0.02\n",
        "\n",
        "    prevented_fraud = tp * avg_fraud_amount * fraud_multiplier\n",
        "    missed_fraud = fn * avg_fraud_amount * fraud_multiplier\n",
        "    investigation_costs = (tp + fp) * investigation_cost\n",
        "    customer_friction = fp * avg_fraud_amount * friction_rate\n",
        "\n",
        "    net_benefit = prevented_fraud - missed_fraud - investigation_costs - customer_friction\n",
        "\n",
        "    total_fraud = (tp + fn) * avg_fraud_amount * fraud_multiplier\n",
        "    savings = prevented_fraud - investigation_costs - customer_friction\n",
        "\n",
        "    roi = (savings / (investigation_costs + customer_friction)) * 100 if investigation_costs > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'prevented_fraud': prevented_fraud,\n",
        "        'missed_fraud': missed_fraud,\n",
        "        'investigation_costs': investigation_costs,\n",
        "        'customer_friction': customer_friction,\n",
        "        'net_benefit': net_benefit,\n",
        "        'total_possible_fraud': total_fraud,\n",
        "        'savings_vs_no_model': savings,\n",
        "        'roi': roi,\n",
        "        'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn\n",
        "    }\n",
        "\n",
        "business_metrics = calculate_business_metrics(y_test, y_test_pred, y_test_proba)\n",
        "\n",
        "print(\"üí∞ Business Impact Analysis\")\n",
        "print(f\"\\nüìä Detection Performance:\")\n",
        "print(f\"    Frauds Detected: {business_metrics['tp']}/{business_metrics['tp']+business_metrics['fn']} ({business_metrics['tp']/(business_metrics['tp']+business_metrics['fn'])*100:.1f}%)\")\n",
        "print(f\"    False Alarms: {business_metrics['fp']}\")\n",
        "print(f\"    Correct Rejections: {business_metrics['tn']:,}\")\n",
        "\n",
        "print(f\"\\nüíµ Financial Impact:\")\n",
        "print(f\"    Prevented Fraud Loss: ${business_metrics['prevented_fraud']:,.2f}\")\n",
        "print(f\"    Missed Fraud Loss: ${business_metrics['missed_fraud']:,.2f}\")\n",
        "print(f\"    Investigation Costs: ${business_metrics['investigation_costs']:,.2f}\")\n",
        "print(f\"    Customer Friction: ${business_metrics['customer_friction']:,.2f}\")\n",
        "print(f\"\\n   üí∞ NET BENEFIT: ${business_metrics['net_benefit']:,.2f}\")\n",
        "print(f\"   üìà ROI: {business_metrics['roi']:.1f}%\")\n",
        "\n",
        "annual_multiplier = 365 / 2\n",
        "annual_benefit = business_metrics['net_benefit'] * annual_multiplier\n",
        "\n",
        "print(f\"\\nüìÖ Annual Projection:\")\n",
        "print(f\"    Annual Net Benefit: ${annual_benefit:,.2f}\")\n",
        "print(f\"    Annual Savings: ${business_metrics['savings_vs_no_model'] * annual_multiplier:,.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmHOTo6eMS00"
      },
      "outputs": [],
      "source": [
        "final_model.save_model('fraud_detection_final.cbm')\n",
        "\n",
        "importance_df.to_csv('feature_importance.csv', index=False)\n",
        "\n",
        "metrics_summary = pd.DataFrame([test_metrics])\n",
        "metrics_summary.to_csv('model_metrics.csv', index=False)\n",
        "\n",
        "business_df = pd.DataFrame([business_metrics])\n",
        "business_df.to_csv('business_impact.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "isp_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}